{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load explore and PreProcess ComplexWebQuestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we load and explore the ComplexWebQuestions dataset.\n",
    "We also preprocess this dataset based on this exploration towards feeding it into a question answering model. Our model is a MAC attention network and thus it's highly dependant on our questions and KB (snippets) respresentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#!pip3 install --user tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/u14303/NLPproject/Data/'\n",
    "FNAME_TRAIN_QUESTION = 'ComplexWebQuestions_train.json'\n",
    "FNAME_DEV_QUESTION = 'ComplexWebQuestions_dev.json'\n",
    "FNAME_TEST_QUESTION = 'ComplexWebQuestions_test.json'\n",
    "\n",
    "FNAME_TRAIN_SNIPPETS = 'web_snippets_train.json'\n",
    "FNAME_DEV_SNIPPETS = 'web_snippets_dev.json'\n",
    "FNAME_TEST_SNIPPETS = 'web_snippets_test.json'\n",
    "\n",
    "FNAME_ANSWERES = 'possible_answers_web_snippets_dev.json'\n",
    "EMBEDDING_DIM = 300\n",
    "FNAME_EMBEDDINGS = 'glove.6B.{}d.txt'.format(EMBEDDING_DIM)\n",
    "FNAME_TOKEN_EMBEDDING_MAT = 'embedding_matrix.dat'\n",
    "\n",
    "FNAME_TOKENIZER = 'tokenizer.pickle'\n",
    "FNAME_INVERSE_MAP = 'inverse_word_token_map.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Questions and Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training questions...\n",
      "Done. Read 27639 questions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training questions...\")\n",
    "with open(os.path.join(DATA_PATH, FNAME_TRAIN_QUESTION), \"r\") as f:\n",
    "    train_questions = pd.read_json(f)\n",
    "print(\"Done. Read {} questions.\".format(train_questions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dev data...\n",
      "Done. Read 3519 questions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dev data...\")\n",
    "with open(os.path.join(DATA_PATH, FNAME_DEV_QUESTION), \"r\") as f:\n",
    "    dev_questions = pd.read_json(f)\n",
    "print(\"Done. Read {} questions.\".format(dev_questions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test questions...\n",
      "Done. Read 3531 questions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test questions...\")\n",
    "with open(os.path.join(DATA_PATH, FNAME_TEST_QUESTION), \"r\") as f:\n",
    "    test_questions = pd.read_json(f)\n",
    "print(\"Done. Read {} questions.\".format(test_questions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric diff between train_cols and dev_cols is: set()\n",
      "Symmetric diff between dev_cols and test_cols is: {'composition_answer', 'answers'}\n"
     ]
    }
   ],
   "source": [
    "train_cols = set(train_questions.columns.values)\n",
    "dev_cols = set(dev_questions.columns.values)\n",
    "test_cols = set(test_questions.columns.values)\n",
    "print(\"Symmetric diff between train_cols and dev_cols is:\", train_cols.symmetric_difference(dev_cols))\n",
    "print(\"Symmetric diff between dev_cols and test_cols is:\", dev_cols.symmetric_difference(test_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the questions a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answers</th>\n",
       "      <th>composition_answer</th>\n",
       "      <th>compositionality_type</th>\n",
       "      <th>created</th>\n",
       "      <th>machine_question</th>\n",
       "      <th>question</th>\n",
       "      <th>sparql</th>\n",
       "      <th>webqsp_ID</th>\n",
       "      <th>webqsp_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WebQTrn-3513_7c4117891abf63781b892537979054c6</td>\n",
       "      <td>[{'aliases': ['Washington D.C.', 'Washington',...</td>\n",
       "      <td>george washington university</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T02:07:47</td>\n",
       "      <td>what state is the the education institution ha...</td>\n",
       "      <td>What state is home to the university that is r...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-3513</td>\n",
       "      <td>what state is the george washington university in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WebQTrn-2136_d95da5fb8a16d81fe56cd4ce00843254</td>\n",
       "      <td>[{'aliases': ['Super Bowl 2013', 'Super Bowl 4...</td>\n",
       "      <td>baltimore ravens</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-12T23:27:26</td>\n",
       "      <td>what year did the sports team with the fight s...</td>\n",
       "      <td>What year did the team with Baltimore Fight So...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2136</td>\n",
       "      <td>what year did baltimore ravens win the superbowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WebQTrn-2360_a40a0d50b9a1006e2d254705d46345ea</td>\n",
       "      <td>[{'aliases': ['University of Florida Gators Me...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-12T23:49:23</td>\n",
       "      <td>what football teams did emmitt smith play for ...</td>\n",
       "      <td>Which school with the fight song \"The Orange a...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2360</td>\n",
       "      <td>what football teams did emmitt smith play for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ID  \\\n",
       "0  WebQTrn-3513_7c4117891abf63781b892537979054c6   \n",
       "1  WebQTrn-2136_d95da5fb8a16d81fe56cd4ce00843254   \n",
       "2  WebQTrn-2360_a40a0d50b9a1006e2d254705d46345ea   \n",
       "\n",
       "                                             answers  \\\n",
       "0  [{'aliases': ['Washington D.C.', 'Washington',...   \n",
       "1  [{'aliases': ['Super Bowl 2013', 'Super Bowl 4...   \n",
       "2  [{'aliases': ['University of Florida Gators Me...   \n",
       "\n",
       "             composition_answer compositionality_type              created  \\\n",
       "0  george washington university           composition  2018-02-13T02:07:47   \n",
       "1              baltimore ravens           composition  2018-02-12T23:27:26   \n",
       "2                                         conjunction  2018-02-12T23:49:23   \n",
       "\n",
       "                                    machine_question  \\\n",
       "0  what state is the the education institution ha...   \n",
       "1  what year did the sports team with the fight s...   \n",
       "2  what football teams did emmitt smith play for ...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What state is home to the university that is r...   \n",
       "1  What year did the team with Baltimore Fight So...   \n",
       "2  Which school with the fight song \"The Orange a...   \n",
       "\n",
       "                                              sparql     webqsp_ID  \\\n",
       "0  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...  WebQTrn-3513   \n",
       "1  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...  WebQTrn-2136   \n",
       "2  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...  WebQTrn-2360   \n",
       "\n",
       "                                     webqsp_question  \n",
       "0  what state is the george washington university in  \n",
       "1   what year did baltimore ravens win the superbowl  \n",
       "2      what football teams did emmitt smith play for  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27639 records in train_questions, but only 27628 unique train questions and 27639 unique train question IDs.\n",
      "There are 3519 records in dev_questions, but only 3519 unique dev questions and 3519 unique dev question IDs.\n",
      "There are 3531 records in test_questions, but only 3531 unique test questions and 3531 unique test question IDs.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} records in train_questions, but only {} unique train questions and {} unique train question IDs.\".format(train_questions.shape[0],\n",
    "                                                                                                                      train_questions[\"question\"].nunique(),\n",
    "                                                                                                                      train_questions[\"ID\"].nunique()))\n",
    "print(\"There are {} records in dev_questions, but only {} unique dev questions and {} unique dev question IDs.\".format(dev_questions.shape[0],\n",
    "                                                                                                                      dev_questions[\"question\"].nunique(),\n",
    "                                                                                                                      dev_questions[\"ID\"].nunique()))\n",
    "print(\"There are {} records in test_questions, but only {} unique test questions and {} unique test question IDs.\".format(test_questions.shape[0],\n",
    "                                                                                                                         test_questions[\"question\"].nunique(),\n",
    "                                                                                                                         test_questions[\"ID\"].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.388999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.170039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_len\n",
       "count  34689.000000\n",
       "mean      13.388999\n",
       "std        3.170039\n",
       "min        3.000000\n",
       "25%       11.000000\n",
       "50%       13.000000\n",
       "75%       15.000000\n",
       "max       30.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% precent of the questions are shorter than 19.0 words and 99% are shorter than 21.0 words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions = pd.concat([train_questions, dev_questions, test_questions], axis = 0, sort=True, ignore_index=True)\n",
    "all_questions[\"question_len\"] = all_questions.apply(lambda r : len(r[\"question\"].split(' ')), axis=1)\n",
    "\n",
    "display(all_questions[[\"question_len\"]].describe())\n",
    "print(\"95% precent of the questions are shorter than {} words and 99% are shorter than {} words.\".format(\n",
    "    all_questions[\"question_len\"].quantile(0.95),\n",
    "    all_questions[\"question_len\"].quantile(0.99)))\n",
    "\n",
    "del all_questions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the answers (relevant for tain and dev only).\n",
    "\n",
    "Extract answers and aliases to seperate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Washington, D.C.\n",
       "1           Super Bowl XLVII\n",
       "2    Florida Gators football\n",
       "3                 Gridlock'd\n",
       "4                   Portugal\n",
       "Name: answer, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    [Washington, D.C., Washington D.C., Washington...\n",
       "1    [Super Bowl XLVII, Super Bowl 2013, Super Bowl...\n",
       "2    [Florida Gators football, University of Florid...\n",
       "3                                         [Gridlock'd]\n",
       "4                      [Portugal, Portuguese Republic]\n",
       "Name: merged_answers, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0                    Muhammad Zia-ul-Haq\n",
       "1    Vanderbilt University Mr. Commodore\n",
       "2                                 Brazil\n",
       "3                          John Harbaugh\n",
       "4                             Jeff Faine\n",
       "Name: answer, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0                                [Muhammad Zia-ul-Haq]\n",
       "1                [Vanderbilt University Mr. Commodore]\n",
       "2    [Brazil, Brazilian , República Federativa do B...\n",
       "3                                      [John Harbaugh]\n",
       "4                  [Jeff Faine, Braylon Jamel Edwards]\n",
       "Name: merged_answers, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_questions[\"answer\"] = train_questions.apply(lambda r:r[\"answers\"][0][\"answer\"], axis = 1)\n",
    "display(train_questions[\"answer\"][:5])\n",
    "train_questions[\"merged_answers\"] = train_questions.apply(lambda r:[r[\"answers\"][0][\"answer\"]] + r[\"answers\"][0][\"aliases\"], axis = 1)\n",
    "display(train_questions[\"merged_answers\"][:5])\n",
    "\n",
    "dev_questions[\"answer\"] = dev_questions.apply(lambda r:r[\"answers\"][0][\"answer\"], axis = 1)\n",
    "display(dev_questions[\"answer\"][:5])\n",
    "dev_questions[\"merged_answers\"] = dev_questions.apply(lambda r:[r[\"answers\"][0][\"answer\"]] + r[\"answers\"][0][\"aliases\"], axis = 1)\n",
    "display(dev_questions[\"merged_answers\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all questions with no answer (surprisingly, there are some!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_questions, dev_questions]:\n",
    "    df.dropna(subset=['answer'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_questions = pd.concat([train_questions, dev_questions], axis = 0, sort=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged_answers</th>\n",
       "      <th>num_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Washington, D.C., Washington D.C., Washington...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Super Bowl XLVII, Super Bowl 2013, Super Bowl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Florida Gators football, University of Florid...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Gridlock'd]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Portugal, Portuguese Republic]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      merged_answers  num_answers\n",
       "0  [Washington, D.C., Washington D.C., Washington...            9\n",
       "1  [Super Bowl XLVII, Super Bowl 2013, Super Bowl...            3\n",
       "2  [Florida Gators football, University of Florid...           22\n",
       "3                                       [Gridlock'd]            1\n",
       "4                    [Portugal, Portuguese Republic]            2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.943809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.282474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_answers\n",
       "count  31144.000000\n",
       "mean       3.943809\n",
       "std        4.282474\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        3.000000\n",
       "75%        5.000000\n",
       "max       61.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% precent of the questions have less than 12.0 answers 99% have less than 22.0.\n"
     ]
    }
   ],
   "source": [
    "train_dev_questions[\"num_answers\"] = train_dev_questions.apply(lambda r:len(r[\"merged_answers\"]), axis = 1)\n",
    "display(train_dev_questions[[\"merged_answers\", \"num_answers\"]].head(5))\n",
    "display(train_dev_questions[[\"num_answers\"]].describe())\n",
    "print(\"95% precent of the questions have less than {} answers 99% have less than {}.\".format(\n",
    "    train_dev_questions[\"num_answers\"].quantile(0.95) + 1,\n",
    "    train_dev_questions[\"num_answers\"].quantile(0.99) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31144 train+dev question records, 31144 unique questions, but only 3805 unique explicit answers.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} train+dev question records, {} unique questions, but only {} unique explicit answers.\".format(\n",
    "    train_dev_questions.shape[0],\n",
    "    train_dev_questions[\"ID\"].nunique(),\n",
    "    train_dev_questions[\"answer\"].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "train_unique_ans = set(itertools.chain.from_iterable(train_questions[\"merged_answers\"].tolist()))\n",
    "dev_unique_ans = set(itertools.chain.from_iterable(dev_questions[\"merged_answers\"].tolist()))\n",
    "mutual_answers = train_unique_ans.intersection(dev_unique_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27625 train questions and 3519 dev questions.\n",
      "10952 unique train answers (incl. aliases).\n",
      "2380 unique dev answers.\n",
      "1288 mutual unique answers.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} train questions and {} dev questions.\\n{} unique train answers (incl. aliases).\\n{} unique dev answers.\\n{} mutual unique answers.\".format(\n",
    "    train_questions.shape[0],\n",
    "    dev_questions.shape[0],\n",
    "    len(train_unique_ans),\n",
    "    len(dev_unique_ans),\n",
    "    len(mutual_answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceck what are the lengths of the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ans_lens(answers):\n",
    "    res = []\n",
    "    for ans in answers:\n",
    "        res.append(len(ans.split()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dev_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-c473e7981d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dev_questions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_ans_len\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dev_questions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_ans_lens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"merged_answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_dev_questions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"avg_ans_len\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dev_questions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_ans_lens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"merged_answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_dev_questions[\"has_ans_with_less_than_n\"] = train_dev_questions.apply(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dev_questions' is not defined"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "\n",
    "train_dev_questions[\"max_ans_len\"] = train_dev_questions.apply(lambda r : max(calc_ans_lens(r[\"merged_answers\"])), axis=1)\n",
    "train_dev_questions[\"avg_ans_len\"] = train_dev_questions.apply(lambda r : np.average(calc_ans_lens(r[\"merged_answers\"])), axis=1)\n",
    "train_dev_questions[\"has_ans_with_less_than_n\"] = train_dev_questions.apply(\n",
    "    lambda r : np.any(n > np.array(calc_ans_lens(r[\"merged_answers\"]))), axis=1)\n",
    "display(train_dev_questions[[\"max_ans_len\", \"avg_ans_len\"]].describe())\n",
    "\n",
    "print(\"95% precent of the questions are shorter than {} words and 99% are shorter than {} words.\".format(\n",
    "    train_dev_questions[\"max_ans_len\"].quantile(0.95),\n",
    "    train_dev_questions[\"max_ans_len\"].quantile(0.99)))\n",
    "print(\"{}% of the questions have an answer shorter than {} words.\".format(\n",
    "    100 * train_dev_questions[train_dev_questions[\"has_ans_with_less_than_n\"] == True].shape[0] /\n",
    "    train_dev_questions[\"has_ans_with_less_than_n\"].shape[0], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_dev_questions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with questions for which we have an answer longer than n=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_answers_longer_than_n(answers):\n",
    "    res = []\n",
    "    for ans in answers:\n",
    "        if len(ans.split()) < n:\n",
    "            res.append(ans)\n",
    "    if len(res) == 0:\n",
    "        return np.nan\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_questions[\"answers_shorter_than_n\"] = train_questions.apply(lambda r : filter_answers_longer_than_n(r[\"merged_answers\"]), axis=1)\n",
    "dev_questions[\"answers_shorter_than_n\"] = dev_questions.apply(lambda r : filter_answers_longer_than_n(r[\"merged_answers\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also delete all questions with no short answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_questions, dev_questions]:\n",
    "    df.dropna(subset=['answers_shorter_than_n'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train snippets...\n",
      "Done. Read snippets for 107743 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading train snippets...\")\n",
    "with open(os.path.join(DATA_PATH, FNAME_TRAIN_SNIPPETS), \"r\") as f:\n",
    "    train_snippets = pd.read_json(f)\n",
    "print(\"Done. Read snippets for {} records\".format(len(train_snippets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dev snippets...\n",
      "Done. Read snippets for 14446 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dev snippets...\")\n",
    "with open(os.path.join(DATA_PATH, FNAME_DEV_SNIPPETS), \"r\") as f:\n",
    "    dev_snippets = pd.read_json(f)\n",
    "print(\"Done. Read snippets for {} records\".format(len(dev_snippets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test snippets...\n",
      "Done. Read snippets for 14338 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test snippets...\")\n",
    "with open(os.path.join(DATA_PATH, FNAME_TEST_SNIPPETS), \"r\") as f:\n",
    "    test_snippets = pd.read_json(f)\n",
    "print(\"Done. Read snippets for {} records\".format(len(test_snippets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_ID</th>\n",
       "      <th>split_source</th>\n",
       "      <th>web_query</th>\n",
       "      <th>web_snippets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Billie Jean\"'s composer was born where?</td>\n",
       "      <td>WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c</td>\n",
       "      <td>[noisy supervision split, ptrnet split]</td>\n",
       "      <td>\"Billie Jean\"'s composer was born where</td>\n",
       "      <td>[{'snippet': '\"Billie Jean\" is a 1982 song by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Just Like Starting Over\"'s composer plays wha...</td>\n",
       "      <td>WebQTest-84_355ab1c8f8cb13542c4f8e137e429342</td>\n",
       "      <td>[noisy supervision split, ptrnet split]</td>\n",
       "      <td>\"Just Like Starting Over\"'s composer plays wha...</td>\n",
       "      <td>[{'snippet': '\"(Just Like) Starting Over\" is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The Fourth Hand\" author also wrote what other...</td>\n",
       "      <td>WebQTest-449_d12a8796bf4c6c36c9d2d9ee1186ba20</td>\n",
       "      <td>[noisy supervision split, ptrnet split]</td>\n",
       "      <td>\"The Fourth Hand\" author also wrote what other...</td>\n",
       "      <td>[{'snippet': 'The Fourth Hand is a 2001 novel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"The salvation of the world is in man's suffer...</td>\n",
       "      <td>WebQTrn-1971_f1bb78925b7b947a056544194a413bb5</td>\n",
       "      <td>[noisy supervision split, ptrnet split]</td>\n",
       "      <td>\"The salvation of the world is in man's suffer...</td>\n",
       "      <td>[{'snippet': 'In the light of what He has done...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"What is the educational background of the Whi...</td>\n",
       "      <td>WebQTrn-2805_8c4cd2a8dd5064dcd1e88389796138c7</td>\n",
       "      <td>[noisy supervision split, ptrnet split]</td>\n",
       "      <td>\"What is the educational background of the Whi...</td>\n",
       "      <td>[{'snippet': 'الانتقال إلى History‏ - Under th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           \"Billie Jean\"'s composer was born where?   \n",
       "1  \"Just Like Starting Over\"'s composer plays wha...   \n",
       "2  \"The Fourth Hand\" author also wrote what other...   \n",
       "3  \"The salvation of the world is in man's suffer...   \n",
       "4  \"What is the educational background of the Whi...   \n",
       "\n",
       "                                      question_ID  \\\n",
       "0  WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c   \n",
       "1    WebQTest-84_355ab1c8f8cb13542c4f8e137e429342   \n",
       "2   WebQTest-449_d12a8796bf4c6c36c9d2d9ee1186ba20   \n",
       "3   WebQTrn-1971_f1bb78925b7b947a056544194a413bb5   \n",
       "4   WebQTrn-2805_8c4cd2a8dd5064dcd1e88389796138c7   \n",
       "\n",
       "                              split_source  \\\n",
       "0  [noisy supervision split, ptrnet split]   \n",
       "1  [noisy supervision split, ptrnet split]   \n",
       "2  [noisy supervision split, ptrnet split]   \n",
       "3  [noisy supervision split, ptrnet split]   \n",
       "4  [noisy supervision split, ptrnet split]   \n",
       "\n",
       "                                           web_query  \\\n",
       "0            \"Billie Jean\"'s composer was born where   \n",
       "1  \"Just Like Starting Over\"'s composer plays wha...   \n",
       "2  \"The Fourth Hand\" author also wrote what other...   \n",
       "3  \"The salvation of the world is in man's suffer...   \n",
       "4  \"What is the educational background of the Whi...   \n",
       "\n",
       "                                        web_snippets  \n",
       "0  [{'snippet': '\"Billie Jean\" is a 1982 song by ...  \n",
       "1  [{'snippet': '\"(Just Like) Starting Over\" is a...  \n",
       "2  [{'snippet': 'The Fourth Hand is a 2001 novel ...  \n",
       "3  [{'snippet': 'In the light of what He has done...  \n",
       "4  [{'snippet': 'الانتقال إلى History‏ - Under th...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_snippets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 107743 records in train_snippets, but only 27627 unique train questions and 27633 unique train question IDs.\n",
      "There are 14446 records in dev_snippets, but only 3519 unique dev questions and 3519 unique dev question IDs.\n",
      "There are 14338 records in test_snippets, but only 3531 unique test questions and 3531 unique test question IDs.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} records in train_snippets, but only {} unique train questions and {} unique train question IDs.\".format(train_snippets.shape[0],\n",
    "                                                                                                                      train_snippets[\"question\"].nunique(),\n",
    "                                                                                                                      train_snippets[\"question_ID\"].nunique()))\n",
    "print(\"There are {} records in dev_snippets, but only {} unique dev questions and {} unique dev question IDs.\".format(dev_snippets.shape[0],\n",
    "                                                                                                                      dev_snippets[\"question\"].nunique(),\n",
    "                                                                                                                      dev_snippets[\"question_ID\"].nunique()))\n",
    "print(\"There are {} records in test_snippets, but only {} unique test questions and {} unique test question IDs.\".format(test_snippets.shape[0],\n",
    "                                                                                                                         test_snippets[\"question\"].nunique(),\n",
    "                                                                                                                         test_snippets[\"question_ID\"].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are ~4 records for each unique question ID in each snippet dataset. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_ID</th>\n",
       "      <th>split_source</th>\n",
       "      <th>web_query</th>\n",
       "      <th>web_snippets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Billie Jean\"'s composer was born where?</td>\n",
       "      <td>WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c</td>\n",
       "      <td>[noisy supervision split, ptrnet split]</td>\n",
       "      <td>\"Billie Jean\"'s composer was born where</td>\n",
       "      <td>[{'snippet': '\"Billie Jean\" is a 1982 song by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69529</th>\n",
       "      <td>\"Billie Jean\"'s composer was born where?</td>\n",
       "      <td>WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c</td>\n",
       "      <td>[noisy supervision split]</td>\n",
       "      <td>`` Billie Jean '' 's composer</td>\n",
       "      <td>[{'snippet': 'According to Inside the Hits, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69530</th>\n",
       "      <td>\"Billie Jean\"'s composer was born where?</td>\n",
       "      <td>WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c</td>\n",
       "      <td>[ptrnet split]</td>\n",
       "      <td>`` Billie Jean '''s composer</td>\n",
       "      <td>[{'snippet': '\"Billie Jean\" is a song by Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82532</th>\n",
       "      <td>\"Billie Jean\"'s composer was born where?</td>\n",
       "      <td>WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c</td>\n",
       "      <td>[noisy supervision split, ptrnet split]</td>\n",
       "      <td>michael jackson was born where</td>\n",
       "      <td>[{'snippet': 'Singer-songwriter Michael Jackso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question  \\\n",
       "0      \"Billie Jean\"'s composer was born where?   \n",
       "69529  \"Billie Jean\"'s composer was born where?   \n",
       "69530  \"Billie Jean\"'s composer was born where?   \n",
       "82532  \"Billie Jean\"'s composer was born where?   \n",
       "\n",
       "                                          question_ID  \\\n",
       "0      WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c   \n",
       "69529  WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c   \n",
       "69530  WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c   \n",
       "82532  WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c   \n",
       "\n",
       "                                  split_source  \\\n",
       "0      [noisy supervision split, ptrnet split]   \n",
       "69529                [noisy supervision split]   \n",
       "69530                           [ptrnet split]   \n",
       "82532  [noisy supervision split, ptrnet split]   \n",
       "\n",
       "                                     web_query  \\\n",
       "0      \"Billie Jean\"'s composer was born where   \n",
       "69529            `` Billie Jean '' 's composer   \n",
       "69530             `` Billie Jean '''s composer   \n",
       "82532           michael jackson was born where   \n",
       "\n",
       "                                            web_snippets  \n",
       "0      [{'snippet': '\"Billie Jean\" is a 1982 song by ...  \n",
       "69529  [{'snippet': 'According to Inside the Hits, th...  \n",
       "69530  [{'snippet': '\"Billie Jean\" is a song by Ameri...  \n",
       "82532  [{'snippet': 'Singer-songwriter Michael Jackso...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_snippets[\"question_ID\"] = train_snippets[\"question_ID\"].astype('str')\n",
    "idd = \"WebQTest-1796_293ff6fdbda2c0c1c40a4c6ac6cef62c\"\n",
    "train_snippets[train_snippets[\"question_ID\"] == idd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This apparently happens because for each question several different web queries were made as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore snippet's lengthes for padding purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snippets = pd.concat([test_snippets, dev_snippets, train_snippets], axis = 0, sort=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snippets[\"web_snippets_avg_len\"] = all_snippets.apply(\n",
    "    lambda r: np.average([0]+[len(snippet['snippet'].split(' ')) for snippet in r[\"web_snippets\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snippets[\"web_snippets_max_len\"] = all_snippets.apply(\n",
    "    lambda r: np.max([0]+[len(snippet['snippet'].split(' ')) for snippet in r[\"web_snippets\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_snippets[\"web_snippets_095_precentile_len\"] = all_snippets.apply(\n",
    "    lambda r: np.percentile([0]+[len(snippet['snippet'].split(' ')) for snippet in r[\"web_snippets\"]], 95), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web_snippets_avg_len</th>\n",
       "      <th>web_snippets_max_len</th>\n",
       "      <th>web_snippets_095_precentile_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>136527.000000</td>\n",
       "      <td>136527.000000</td>\n",
       "      <td>136527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.457214</td>\n",
       "      <td>68.734485</td>\n",
       "      <td>62.915131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.439846</td>\n",
       "      <td>14.102876</td>\n",
       "      <td>12.092190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.980000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.910891</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.287129</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.500000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>222.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       web_snippets_avg_len  web_snippets_max_len  \\\n",
       "count         136527.000000         136527.000000   \n",
       "mean              50.457214             68.734485   \n",
       "std               10.439846             14.102876   \n",
       "min                0.000000              0.000000   \n",
       "25%               46.980000             63.000000   \n",
       "50%               49.910891             65.000000   \n",
       "75%               52.287129             69.000000   \n",
       "max               98.500000            389.000000   \n",
       "\n",
       "       web_snippets_095_precentile_len  \n",
       "count                    136527.000000  \n",
       "mean                         62.915131  \n",
       "std                          12.092190  \n",
       "min                           0.000000  \n",
       "25%                          59.000000  \n",
       "50%                          61.000000  \n",
       "75%                          63.000000  \n",
       "max                         222.900000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_snippets[[\"web_snippets_avg_len\", \"web_snippets_max_len\", \"web_snippets_095_precentile_len\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's safe to conclude that we can pad/clamp each snippet to the size of 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del all_snippets\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all titles and snippets for each record into one text string, lower case it and save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also try keeping the top k snippets of each record in the snippets dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "delim = '. '\n",
    "k=10\n",
    "for df in [test_snippets, dev_snippets, train_snippets]:\n",
    "#     df[\"merged_titles_and_snippets\"] = df.apply(\n",
    "#         lambda r: [snippet['title'] + delim + snippet['snippet'] for snippet in r[\"web_snippets\"]],\n",
    "#         axis=1)\n",
    "#     df[\"merged_titles_and_snippets_len\"] = df.apply(lambda r: len(r[\"merged_titles_and_snippets\"].split(' ')), axis = 1)\n",
    "    df[\"merged_k_reduced_titles_and_snippets\"] = df.apply(\n",
    "        lambda r: [snippet['title'] + delim + snippet['snippet'] for snippet in r[\"web_snippets\"][:k]],\n",
    "        axis=1)\n",
    "    df[\"merged_k_reduced_titles_and_snippets_len\"] = df.apply(\n",
    "        lambda r: np.sum([len(snip.split(' ')) for snip in r[\"merged_k_reduced_titles_and_snippets\"]]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged_k_reduced_titles_and_snippets_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>136527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>578.672131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>121.943420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>531.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>579.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1086.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       merged_k_reduced_titles_and_snippets_len\n",
       "count                             136527.000000\n",
       "mean                                 578.672131\n",
       "std                                  121.943420\n",
       "min                                    0.000000\n",
       "25%                                  531.000000\n",
       "50%                                  579.000000\n",
       "75%                                  620.000000\n",
       "max                                 1086.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% precent of the snippets are shorter than 824.0 and 99% are shorter than 894.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_snippets = pd.concat([test_snippets, dev_snippets, train_snippets], axis = 0, sort=True, ignore_index=True)\n",
    "# display(all_snippets[[\"merged_titles_and_snippets_len\"]].describe())\n",
    "# print(\"95% precent of the snippets are shorter than {} and 99% are shorter than {}\".format(\n",
    "#     all_snippets[\"merged_titles_and_snippets_len\"].quantile(0.95),\n",
    "#     all_snippets[\"merged_titles_and_snippets_len\"].quantile(0.99)))\n",
    "\n",
    "display(all_snippets[[\"merged_k_reduced_titles_and_snippets_len\"]].describe())\n",
    "print(\"95% precent of the snippets are shorter than {} and 99% are shorter than {}\".format(\n",
    "    all_snippets[\"merged_k_reduced_titles_and_snippets_len\"].quantile(0.95),\n",
    "    all_snippets[\"merged_k_reduced_titles_and_snippets_len\"].quantile(0.99)))\n",
    "del all_snippets\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to reduce (merge) all snippets by ID.\n",
    "\n",
    "The resulting dataframe will have a unique question_ID per record, and all relevant snippets in the same record (and also the top k * num_of_web_queries_per_question snippets per each question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snippets_merged_by_ID = pd.DataFrame(train_questions[[\"ID\", \"question\"]])\n",
    "dev_snippets_merged_by_ID = pd.DataFrame(dev_questions[[\"ID\", \"question\"]])\n",
    "test_snippets_merged_by_ID = pd.DataFrame(test_questions[[\"ID\", \"question\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_snippets(all_rows_per_id):\n",
    "    return list(itertools.chain.from_iterable(all_rows_per_id[\"merged_k_reduced_titles_and_snippets\"].tolist()))\n",
    "\n",
    "for merged, unmerged in [(train_snippets_merged_by_ID, train_snippets), (dev_snippets_merged_by_ID, dev_snippets), (test_snippets_merged_by_ID, test_snippets)]:\n",
    "    merged[\"merged_top_k_snippets\"] = merged.apply(\n",
    "             lambda r: merge_snippets(unmerged[unmerged[\"question_ID\"] == r[\"ID\"]]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    26115.000000\n",
      "mean        38.395443\n",
      "std         11.037102\n",
      "min          0.000000\n",
      "25%         30.000000\n",
      "50%         40.000000\n",
      "75%         50.000000\n",
      "max         50.000000\n",
      "Name: num_of_merged_snippets, dtype: float64\n",
      "count    3149.000000\n",
      "mean       39.150206\n",
      "std        10.194674\n",
      "min         0.000000\n",
      "25%        30.000000\n",
      "50%        40.000000\n",
      "75%        50.000000\n",
      "max        50.000000\n",
      "Name: num_of_merged_snippets, dtype: float64\n",
      "count    3401.000000\n",
      "mean       39.207880\n",
      "std        10.198703\n",
      "min         0.000000\n",
      "25%        30.000000\n",
      "50%        40.000000\n",
      "75%        50.000000\n",
      "max        50.000000\n",
      "Name: num_of_merged_snippets, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for df in [train_snippets_merged_by_ID, dev_snippets_merged_by_ID, test_snippets_merged_by_ID]:\n",
    "    df[\"num_of_merged_snippets\"] =  train_snippets_merged_by_ID.apply(lambda r: len(r[\"merged_top_k_snippets\"]), axis = 1)\n",
    "    print(df[\"num_of_merged_snippets\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pad with empty snippets that all question will have 50 anippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_to = 150\n",
    "pad_to = 50\n",
    "def pad_with_empty(snippets):\n",
    "    pad = [\"aldays ultra\" for i in range(pad_to - len(snippets))]\n",
    "    return snippets + pad\n",
    "\n",
    "for df in [train_snippets_merged_by_ID, dev_snippets_merged_by_ID, test_snippets_merged_by_ID]:\n",
    "    df[\"merged_top_k_snippets\"] = df.apply(\n",
    "             lambda r: pad_with_empty(r[\"merged_top_k_snippets\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    26115.0\n",
      "mean        50.0\n",
      "std          0.0\n",
      "min         50.0\n",
      "25%         50.0\n",
      "50%         50.0\n",
      "75%         50.0\n",
      "max         50.0\n",
      "Name: num_of_merged_snippets, dtype: float64\n",
      "count    3149.0\n",
      "mean       50.0\n",
      "std         0.0\n",
      "min        50.0\n",
      "25%        50.0\n",
      "50%        50.0\n",
      "75%        50.0\n",
      "max        50.0\n",
      "Name: num_of_merged_snippets, dtype: float64\n",
      "count    3401.0\n",
      "mean       50.0\n",
      "std         0.0\n",
      "min        50.0\n",
      "25%        50.0\n",
      "50%        50.0\n",
      "75%        50.0\n",
      "max        50.0\n",
      "Name: num_of_merged_snippets, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for df in [train_snippets_merged_by_ID, dev_snippets_merged_by_ID, test_snippets_merged_by_ID]:\n",
    "    df[\"num_of_merged_snippets\"] =  train_snippets_merged_by_ID.apply(lambda r: len(r[\"merged_top_k_snippets\"]), axis = 1)\n",
    "    print(df[\"num_of_merged_snippets\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padded successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge questions_answers and snippets dataframes into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for which at least one of their snippets contains its explicit answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_snippets.rename(index=str, columns={\"question_ID\": \"ID\"}, inplace=True)\n",
    "train_questions_snippets = train_questions.merge(train_snippets_merged_by_ID, on='ID', how='left')\n",
    "\n",
    "dev_snippets.rename(index=str, columns={\"question_ID\": \"ID\"}, inplace=True)\n",
    "dev_questions_snippets = dev_questions.merge(dev_snippets_merged_by_ID, on='ID', how='left')\n",
    "\n",
    "test_snippets.rename(index=str, columns={\"question_ID\": \"ID\"}, inplace=True)\n",
    "test_questions_snippets = test_questions.merge(test_snippets_merged_by_ID, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_questions_snippets.rename(index=str, columns={\"question_x\": \"question\"}, inplace=True)\n",
    "dev_questions_snippets.rename(index=str, columns={\"question_x\": \"question\"}, inplace=True)\n",
    "test_questions_snippets.rename(index=str, columns={\"question_x\": \"question\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercase all text (questions, answers and snippets) towards following checks and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_questions_snippets, dev_questions_snippets, test_questions_snippets]:\n",
    "    df[\"question\"] = df.apply(lambda r: str(r[\"question\"]).lower(), axis=1)\n",
    "    df[\"merged_top_k_snippets\"] = df.apply(lambda r: [str(snip).lower() for snip in r[\"merged_top_k_snippets\"]], axis=1)\n",
    "    \n",
    "# Lowercase answers.\n",
    "for df in [train_questions_snippets, dev_questions_snippets]:\n",
    "    df[\"answer\"] = df.apply(lambda r: str(r[\"answer\"]).lower(), axis=1)\n",
    "    df[\"answers_shorter_than_n\"] = df.apply(lambda r: [str(ans).lower() for ans in r[\"answers_shorter_than_n\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answers</th>\n",
       "      <th>composition_answer</th>\n",
       "      <th>compositionality_type</th>\n",
       "      <th>created</th>\n",
       "      <th>machine_question</th>\n",
       "      <th>question</th>\n",
       "      <th>sparql</th>\n",
       "      <th>webqsp_ID</th>\n",
       "      <th>webqsp_question</th>\n",
       "      <th>answer</th>\n",
       "      <th>merged_answers</th>\n",
       "      <th>answers_shorter_than_n</th>\n",
       "      <th>question_y</th>\n",
       "      <th>merged_top_k_snippets</th>\n",
       "      <th>num_of_merged_snippets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WebQTrn-3513_7c4117891abf63781b892537979054c6</td>\n",
       "      <td>[{'aliases': ['Washington D.C.', 'Washington',...</td>\n",
       "      <td>george washington university</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T02:07:47</td>\n",
       "      <td>what state is the the education institution ha...</td>\n",
       "      <td>what state is home to the university that is r...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-3513</td>\n",
       "      <td>what state is the george washington university in</td>\n",
       "      <td>washington, d.c.</td>\n",
       "      <td>[Washington, D.C., Washington D.C., Washington...</td>\n",
       "      <td>[washington, d.c., washington d.c., washington...</td>\n",
       "      <td>What state is home to the university that is r...</td>\n",
       "      <td>[gwsports.com mike lonergan bio :: george wash...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WebQTrn-2136_d95da5fb8a16d81fe56cd4ce00843254</td>\n",
       "      <td>[{'aliases': ['Super Bowl 2013', 'Super Bowl 4...</td>\n",
       "      <td>baltimore ravens</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-12T23:27:26</td>\n",
       "      <td>what year did the sports team with the fight s...</td>\n",
       "      <td>what year did the team with baltimore fight so...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2136</td>\n",
       "      <td>what year did baltimore ravens win the superbowl</td>\n",
       "      <td>super bowl xlvii</td>\n",
       "      <td>[Super Bowl XLVII, Super Bowl 2013, Super Bowl...</td>\n",
       "      <td>[super bowl xlvii, super bowl 2013, super bowl...</td>\n",
       "      <td>What year did the team with Baltimore Fight So...</td>\n",
       "      <td>[baltimore ravens fight song - \"the baltimore ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WebQTrn-2360_a40a0d50b9a1006e2d254705d46345ea</td>\n",
       "      <td>[{'aliases': ['University of Florida Gators Me...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-12T23:49:23</td>\n",
       "      <td>what football teams did emmitt smith play for ...</td>\n",
       "      <td>which school with the fight song \"the orange a...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2360</td>\n",
       "      <td>what football teams did emmitt smith play for</td>\n",
       "      <td>florida gators football</td>\n",
       "      <td>[Florida Gators football, University of Florid...</td>\n",
       "      <td>[florida gators football, gators mens football...</td>\n",
       "      <td>Which school with the fight song \"The Orange a...</td>\n",
       "      <td>[florida gators football - the orange and the ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WebQTest-415_b6ad66a3f1f515d0688c346e16d202e6</td>\n",
       "      <td>[{'aliases': [], 'answer': 'Gridlock'd', 'answ...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-13T03:27:47</td>\n",
       "      <td>what movies did tupac star in and is the film ...</td>\n",
       "      <td>what movie with film character named mr. woods...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTest-415</td>\n",
       "      <td>what movies did tupac star in</td>\n",
       "      <td>gridlock'd</td>\n",
       "      <td>[Gridlock'd]</td>\n",
       "      <td>[gridlock'd]</td>\n",
       "      <td>What movie with film character named Mr. Woods...</td>\n",
       "      <td>[the bermuda depths - wikipedia. the bermuda d...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WebQTest-341_0f5ccea2d11b712eda64ebf2f6aeb1ee</td>\n",
       "      <td>[{'aliases': ['Portuguese Republic'], 'answer'...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-13T03:20:47</td>\n",
       "      <td>what countries share borders with spain and is...</td>\n",
       "      <td>what country sharing borders with spain does t...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTest-341</td>\n",
       "      <td>what countries share borders with spain</td>\n",
       "      <td>portugal</td>\n",
       "      <td>[Portugal, Portuguese Republic]</td>\n",
       "      <td>[portugal, portuguese republic]</td>\n",
       "      <td>What country sharing borders with Spain does t...</td>\n",
       "      <td>[which countries border spain? - quora. 07‏/03...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WebQTrn-3239_5e43a21c08076aabc07f1a6fd6ae6bb9</td>\n",
       "      <td>[{'aliases': ['The King'], 'answer': 'Barry Sw...</td>\n",
       "      <td>dallas cowboys</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T01:30:16</td>\n",
       "      <td>who coached the the sports team owner is Jerry...</td>\n",
       "      <td>who was the 1996 coach of the team owned by je...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-3239</td>\n",
       "      <td>who coached the dallas cowboys in 1996</td>\n",
       "      <td>barry switzer</td>\n",
       "      <td>[Barry Switzer, The King]</td>\n",
       "      <td>[barry switzer, the king]</td>\n",
       "      <td>Who was the 1996 coach of the team owned by Je...</td>\n",
       "      <td>[1996 dallas cowboys season - wikipedia. the 1...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WebQTest-1085_1cffc5c553afc1802970e8a6064cac32</td>\n",
       "      <td>[{'aliases': ['Nick', 'Nicholas Joseph \"Nick\" ...</td>\n",
       "      <td>demi lovato</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T04:40:27</td>\n",
       "      <td>who was the artist had a concert tour named De...</td>\n",
       "      <td>who dated the performer who headlined the conc...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTest-1085</td>\n",
       "      <td>who was demi lovato dating</td>\n",
       "      <td>nicholas braun</td>\n",
       "      <td>[Nicholas Braun, Nick, Nicholas Joseph \"Nick\" ...</td>\n",
       "      <td>[nicholas braun, nick, nicholas joseph braun, ...</td>\n",
       "      <td>Who dated the performer who headlined the conc...</td>\n",
       "      <td>[who has demi lovato dated? | popsugar latina....</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WebQTrn-2581_321be15dae483ed949b74cf01e259708</td>\n",
       "      <td>[{'aliases': ['Manchester United', 'Manchester...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-13T00:14:23</td>\n",
       "      <td>who has tim howard played for and the sports t...</td>\n",
       "      <td>which team owned by malcolm glazer has tim how...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2581</td>\n",
       "      <td>who has tim howard played for</td>\n",
       "      <td>manchester united f.c.</td>\n",
       "      <td>[Manchester United F.C., Manchester United, Ma...</td>\n",
       "      <td>[manchester united f.c., manchester united, ma...</td>\n",
       "      <td>Which team owned by Malcolm Glazer has Tim How...</td>\n",
       "      <td>[malcolm glazer - wikipedia. malcolm irving gl...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WebQTrn-2773_7f835727d3cecbcb6c6b48db1fe147b9</td>\n",
       "      <td>[{'aliases': ['Businesswoman', 'Business perso...</td>\n",
       "      <td>henry ford</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T00:40:08</td>\n",
       "      <td>what was the person education institution is D...</td>\n",
       "      <td>what business titles was the most famous alumn...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2773</td>\n",
       "      <td>what was henry ford best known for</td>\n",
       "      <td>businessperson</td>\n",
       "      <td>[Businessperson, Businesswoman, Business perso...</td>\n",
       "      <td>[businessperson, businesswoman, business perso...</td>\n",
       "      <td>What business titles was the most famous alumn...</td>\n",
       "      <td>[these are the most famous university of michi...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebQTrn-2518_1ef15e22372df70baf01b72850deb14d</td>\n",
       "      <td>[{'aliases': ['Korkuluk', 'Yero', 'Scarecrow',...</td>\n",
       "      <td>michael jackson</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T00:05:04</td>\n",
       "      <td>who did the artist had a concert tour named HI...</td>\n",
       "      <td>the artist from the history world tour concert...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2518</td>\n",
       "      <td>who did michael jackson play in the wiz</td>\n",
       "      <td>scarecrow</td>\n",
       "      <td>[Scarecrow, Korkuluk, Yero, Scarecrow, Fiyero]</td>\n",
       "      <td>[scarecrow, korkuluk, yero, scarecrow, fiyero]</td>\n",
       "      <td>The artist from the HIStory World Tour concert...</td>\n",
       "      <td>[history world tour - wikipedia. the history w...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ID  \\\n",
       "0   WebQTrn-3513_7c4117891abf63781b892537979054c6   \n",
       "1   WebQTrn-2136_d95da5fb8a16d81fe56cd4ce00843254   \n",
       "2   WebQTrn-2360_a40a0d50b9a1006e2d254705d46345ea   \n",
       "3   WebQTest-415_b6ad66a3f1f515d0688c346e16d202e6   \n",
       "4   WebQTest-341_0f5ccea2d11b712eda64ebf2f6aeb1ee   \n",
       "5   WebQTrn-3239_5e43a21c08076aabc07f1a6fd6ae6bb9   \n",
       "6  WebQTest-1085_1cffc5c553afc1802970e8a6064cac32   \n",
       "7   WebQTrn-2581_321be15dae483ed949b74cf01e259708   \n",
       "8   WebQTrn-2773_7f835727d3cecbcb6c6b48db1fe147b9   \n",
       "9   WebQTrn-2518_1ef15e22372df70baf01b72850deb14d   \n",
       "\n",
       "                                             answers  \\\n",
       "0  [{'aliases': ['Washington D.C.', 'Washington',...   \n",
       "1  [{'aliases': ['Super Bowl 2013', 'Super Bowl 4...   \n",
       "2  [{'aliases': ['University of Florida Gators Me...   \n",
       "3  [{'aliases': [], 'answer': 'Gridlock'd', 'answ...   \n",
       "4  [{'aliases': ['Portuguese Republic'], 'answer'...   \n",
       "5  [{'aliases': ['The King'], 'answer': 'Barry Sw...   \n",
       "6  [{'aliases': ['Nick', 'Nicholas Joseph \"Nick\" ...   \n",
       "7  [{'aliases': ['Manchester United', 'Manchester...   \n",
       "8  [{'aliases': ['Businesswoman', 'Business perso...   \n",
       "9  [{'aliases': ['Korkuluk', 'Yero', 'Scarecrow',...   \n",
       "\n",
       "             composition_answer compositionality_type              created  \\\n",
       "0  george washington university           composition  2018-02-13T02:07:47   \n",
       "1              baltimore ravens           composition  2018-02-12T23:27:26   \n",
       "2                                         conjunction  2018-02-12T23:49:23   \n",
       "3                                         conjunction  2018-02-13T03:27:47   \n",
       "4                                         conjunction  2018-02-13T03:20:47   \n",
       "5                dallas cowboys           composition  2018-02-13T01:30:16   \n",
       "6                   demi lovato           composition  2018-02-13T04:40:27   \n",
       "7                                         conjunction  2018-02-13T00:14:23   \n",
       "8                    henry ford           composition  2018-02-13T00:40:08   \n",
       "9               michael jackson           composition  2018-02-13T00:05:04   \n",
       "\n",
       "                                    machine_question  \\\n",
       "0  what state is the the education institution ha...   \n",
       "1  what year did the sports team with the fight s...   \n",
       "2  what football teams did emmitt smith play for ...   \n",
       "3  what movies did tupac star in and is the film ...   \n",
       "4  what countries share borders with spain and is...   \n",
       "5  who coached the the sports team owner is Jerry...   \n",
       "6  who was the artist had a concert tour named De...   \n",
       "7  who has tim howard played for and the sports t...   \n",
       "8  what was the person education institution is D...   \n",
       "9  who did the artist had a concert tour named HI...   \n",
       "\n",
       "                                            question  \\\n",
       "0  what state is home to the university that is r...   \n",
       "1  what year did the team with baltimore fight so...   \n",
       "2  which school with the fight song \"the orange a...   \n",
       "3  what movie with film character named mr. woods...   \n",
       "4  what country sharing borders with spain does t...   \n",
       "5  who was the 1996 coach of the team owned by je...   \n",
       "6  who dated the performer who headlined the conc...   \n",
       "7  which team owned by malcolm glazer has tim how...   \n",
       "8  what business titles was the most famous alumn...   \n",
       "9  the artist from the history world tour concert...   \n",
       "\n",
       "                                              sparql      webqsp_ID  \\\n",
       "0  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-3513   \n",
       "1  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-2136   \n",
       "2  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-2360   \n",
       "3  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTest-415   \n",
       "4  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTest-341   \n",
       "5  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-3239   \n",
       "6  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...  WebQTest-1085   \n",
       "7  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-2581   \n",
       "8  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-2773   \n",
       "9  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-2518   \n",
       "\n",
       "                                     webqsp_question                   answer  \\\n",
       "0  what state is the george washington university in         washington, d.c.   \n",
       "1   what year did baltimore ravens win the superbowl         super bowl xlvii   \n",
       "2      what football teams did emmitt smith play for  florida gators football   \n",
       "3                      what movies did tupac star in               gridlock'd   \n",
       "4            what countries share borders with spain                 portugal   \n",
       "5             who coached the dallas cowboys in 1996            barry switzer   \n",
       "6                         who was demi lovato dating           nicholas braun   \n",
       "7                      who has tim howard played for   manchester united f.c.   \n",
       "8                 what was henry ford best known for           businessperson   \n",
       "9            who did michael jackson play in the wiz                scarecrow   \n",
       "\n",
       "                                      merged_answers  \\\n",
       "0  [Washington, D.C., Washington D.C., Washington...   \n",
       "1  [Super Bowl XLVII, Super Bowl 2013, Super Bowl...   \n",
       "2  [Florida Gators football, University of Florid...   \n",
       "3                                       [Gridlock'd]   \n",
       "4                    [Portugal, Portuguese Republic]   \n",
       "5                          [Barry Switzer, The King]   \n",
       "6  [Nicholas Braun, Nick, Nicholas Joseph \"Nick\" ...   \n",
       "7  [Manchester United F.C., Manchester United, Ma...   \n",
       "8  [Businessperson, Businesswoman, Business perso...   \n",
       "9     [Scarecrow, Korkuluk, Yero, Scarecrow, Fiyero]   \n",
       "\n",
       "                              answers_shorter_than_n  \\\n",
       "0  [washington, d.c., washington d.c., washington...   \n",
       "1  [super bowl xlvii, super bowl 2013, super bowl...   \n",
       "2  [florida gators football, gators mens football...   \n",
       "3                                       [gridlock'd]   \n",
       "4                    [portugal, portuguese republic]   \n",
       "5                          [barry switzer, the king]   \n",
       "6  [nicholas braun, nick, nicholas joseph braun, ...   \n",
       "7  [manchester united f.c., manchester united, ma...   \n",
       "8  [businessperson, businesswoman, business perso...   \n",
       "9     [scarecrow, korkuluk, yero, scarecrow, fiyero]   \n",
       "\n",
       "                                          question_y  \\\n",
       "0  What state is home to the university that is r...   \n",
       "1  What year did the team with Baltimore Fight So...   \n",
       "2  Which school with the fight song \"The Orange a...   \n",
       "3  What movie with film character named Mr. Woods...   \n",
       "4  What country sharing borders with Spain does t...   \n",
       "5  Who was the 1996 coach of the team owned by Je...   \n",
       "6  Who dated the performer who headlined the conc...   \n",
       "7  Which team owned by Malcolm Glazer has Tim How...   \n",
       "8  What business titles was the most famous alumn...   \n",
       "9  The artist from the HIStory World Tour concert...   \n",
       "\n",
       "                               merged_top_k_snippets  num_of_merged_snippets  \n",
       "0  [gwsports.com mike lonergan bio :: george wash...                      50  \n",
       "1  [baltimore ravens fight song - \"the baltimore ...                      50  \n",
       "2  [florida gators football - the orange and the ...                      50  \n",
       "3  [the bermuda depths - wikipedia. the bermuda d...                      50  \n",
       "4  [which countries border spain? - quora. 07‏/03...                      50  \n",
       "5  [1996 dallas cowboys season - wikipedia. the 1...                      50  \n",
       "6  [who has demi lovato dated? | popsugar latina....                      50  \n",
       "7  [malcolm glazer - wikipedia. malcolm irving gl...                      50  \n",
       "8  [these are the most famous university of michi...                      50  \n",
       "9  [history world tour - wikipedia. the history w...                      50  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions_snippets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for answers in the snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for df in [train_questions_snippets, dev_questions_snippets]:\n",
    "    df[\"have_explicit_ans_top_k\"] = df.apply(lambda r: r[\"answer\"] in ' '.join(r[\"merged_top_k_snippets\"]),\n",
    "        axis=1)\n",
    "    df[\"have_any_ans_top_k\"] = df.apply(\n",
    "        lambda r: np.any([(answer in ' '.join(r[\"merged_top_k_snippets\"])) for answer in r[\"answers_shorter_than_n\"]]),\n",
    "        axis=1)\n",
    "\n",
    "snippets_questions_answers = pd.concat([train_questions_snippets, dev_questions_snippets], axis = 0, sort=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=10 top snippets and answers shorter than n=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     29384\n",
       "unique        2\n",
       "top        True\n",
       "freq      18235\n",
       "Name: have_explicit_ans_top_k, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.05758235774571% of top 10 merged snippets (18235 snippets) have the explicit answer as a substring in it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     29384\n",
       "unique        2\n",
       "top        True\n",
       "freq      20652\n",
       "Name: have_any_ans_top_k, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.28314729104274% of top 10 merged snippets (20652 snippets) have some answer alias as a substring in it.\n"
     ]
    }
   ],
   "source": [
    "print(\"For k={} top snippets and answers shorter than n={}\".format(k,n))\n",
    "display(snippets_questions_answers[\"have_explicit_ans_top_k\"].describe())\n",
    "have_explicit_ans_top_k = np.count_nonzero(snippets_questions_answers[\"have_explicit_ans_top_k\"])\n",
    "print(\"{}% of top {} merged snippets ({} snippets) have the explicit answer as a substring in it.\".format(have_explicit_ans_top_k*100/snippets_questions_answers.shape[0],\n",
    "                                                                                                          k,\n",
    "                                                                                                          have_explicit_ans_top_k))\n",
    "\n",
    "display(snippets_questions_answers[\"have_any_ans_top_k\"].describe())\n",
    "have_any_ans_top_k = np.count_nonzero(snippets_questions_answers[\"have_any_ans_top_k\"])\n",
    "print(\"{}% of top {} merged snippets ({} snippets) have some answer alias as a substring in it.\".format(have_any_ans_top_k*100/snippets_questions_answers.shape[0],\n",
    "                                                                                                        k,\n",
    "                                                                                                        have_any_ans_top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del snippets_questions_answers\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network we've decided to concentrate only on questions that have some of their answer's aliases as an explicit substring in their top-k snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_ans_train_df = train_questions_snippets.loc[train_questions_snippets[\"have_any_ans_top_k\"] == True]\n",
    "existing_ans_dev_df = dev_questions_snippets.loc[dev_questions_snippets[\"have_any_ans_top_k\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.96745165613632% of test merged snippets (18272 snippets) have some answer alias as a substring in it.\n",
      "72.8051391862955% of dev merged snippets (2380 snippets) have some answer alias as a substring in it.\n"
     ]
    }
   ],
   "source": [
    "print(\"{}% of test merged snippets ({} snippets) have some answer alias as a substring in it.\".format(existing_ans_train_df.shape[0]*100/train_questions_snippets.shape[0], \n",
    "                                                                                                     existing_ans_train_df.shape[0]))\n",
    "print(\"{}% of dev merged snippets ({} snippets) have some answer alias as a substring in it.\".format(existing_ans_dev_df.shape[0]*100/dev_questions_snippets.shape[0], \n",
    "                                                                                                     existing_ans_dev_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answers</th>\n",
       "      <th>composition_answer</th>\n",
       "      <th>compositionality_type</th>\n",
       "      <th>created</th>\n",
       "      <th>machine_question</th>\n",
       "      <th>question</th>\n",
       "      <th>sparql</th>\n",
       "      <th>webqsp_ID</th>\n",
       "      <th>webqsp_question</th>\n",
       "      <th>answer</th>\n",
       "      <th>merged_answers</th>\n",
       "      <th>answers_shorter_than_n</th>\n",
       "      <th>question_y</th>\n",
       "      <th>merged_top_k_snippets</th>\n",
       "      <th>num_of_merged_snippets</th>\n",
       "      <th>have_explicit_ans_top_k</th>\n",
       "      <th>have_any_ans_top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WebQTest-823_ed31f9dd431831dbd32a06b958c7c97c</td>\n",
       "      <td>[{'aliases': ['Brazilian ', 'República Federat...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-13T04:12:26</td>\n",
       "      <td>what does bolivia border and is the country th...</td>\n",
       "      <td>what country borders bolivia and contains goiã¡s?</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTest-823</td>\n",
       "      <td>what does bolivia border</td>\n",
       "      <td>brazil</td>\n",
       "      <td>[Brazil, Brazilian , República Federativa do B...</td>\n",
       "      <td>[brazil, brazilian , brasil]</td>\n",
       "      <td>What country borders Bolivia and contains GoiÃ¡s?</td>\n",
       "      <td>[category:borders of bolivia - wikipedia. page...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WebQTrn-2181_8d86dc5e03446f0e50fd69bc06ae0658</td>\n",
       "      <td>[{'aliases': [], 'answer': 'John Harbaugh', 'a...</td>\n",
       "      <td>ravens</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-12T23:32:26</td>\n",
       "      <td>who is the the sports team owner is Steve Bisc...</td>\n",
       "      <td>who is the coach of the team owned by steve bi...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2181</td>\n",
       "      <td>who is the ravens coach</td>\n",
       "      <td>john harbaugh</td>\n",
       "      <td>[John Harbaugh]</td>\n",
       "      <td>[john harbaugh]</td>\n",
       "      <td>Who is the coach of the team owned by Steve Bi...</td>\n",
       "      <td>[list of baltimore ravens head coaches - wikip...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WebQTrn-1447_f1ea2e60c0bd4311ef47cc0d7f6c0dd8</td>\n",
       "      <td>[{'aliases': ['Braylon Jamel Edwards'], 'answe...</td>\n",
       "      <td></td>\n",
       "      <td>comparative</td>\n",
       "      <td>2018-02-12T22:18:56</td>\n",
       "      <td>who did the cleveland browns draft and is the ...</td>\n",
       "      <td>which professional athletes who began their ca...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-1447</td>\n",
       "      <td>who did the cleveland browns draft</td>\n",
       "      <td>jeff faine</td>\n",
       "      <td>[Jeff Faine, Braylon Jamel Edwards]</td>\n",
       "      <td>[jeff faine, braylon jamel edwards]</td>\n",
       "      <td>Which professional athletes who began their ca...</td>\n",
       "      <td>[what athletes started their career at a relat...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WebQTrn-453_2326103f221042f024262b19814ee9d3</td>\n",
       "      <td>[{'aliases': ['Kenya Shilling'], 'answer': 'Ke...</td>\n",
       "      <td>kenya</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-12T20:29:53</td>\n",
       "      <td>what currency do they accept in the country th...</td>\n",
       "      <td>the country that has the national anthem ee mu...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-453</td>\n",
       "      <td>what currency do they accept in kenya</td>\n",
       "      <td>kenyan shilling</td>\n",
       "      <td>[Kenyan shilling, Kenya Shilling]</td>\n",
       "      <td>[kenyan shilling, kenya shilling]</td>\n",
       "      <td>The country that has the national anthem Ee Mu...</td>\n",
       "      <td>[ee mungu nguvu yetu - wikipedia. ee mungu ngu...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WebQTrn-453_8c50e30ac5163e6dabfc999a7129a4ea</td>\n",
       "      <td>[{'aliases': ['Kenya Shilling'], 'answer': 'Ke...</td>\n",
       "      <td>kenya</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-12T20:29:53</td>\n",
       "      <td>what currency do they accept in the country th...</td>\n",
       "      <td>rift valley province is located in a nation th...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-453</td>\n",
       "      <td>what currency do they accept in kenya</td>\n",
       "      <td>kenyan shilling</td>\n",
       "      <td>[Kenyan shilling, Kenya Shilling]</td>\n",
       "      <td>[kenyan shilling, kenya shilling]</td>\n",
       "      <td>Rift Valley Province is located in a nation th...</td>\n",
       "      <td>[rift valley province - wikipedia. rift valley...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WebQTrn-1929_de8581ad379fdf8fb0e03c89e19ead1a</td>\n",
       "      <td>[{'aliases': ['1923 World'], 'answer': '1923 W...</td>\n",
       "      <td>yankees</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-12T23:08:17</td>\n",
       "      <td>what year did the team won the 1999 World Seri...</td>\n",
       "      <td>when did the champion of the 1999 world series...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-1929</td>\n",
       "      <td>what year did yankees win their first world se...</td>\n",
       "      <td>1923 world series</td>\n",
       "      <td>[1923 World Series, 1923 World]</td>\n",
       "      <td>[1923 world series, 1923 world]</td>\n",
       "      <td>When did the champion of the 1999 World Series...</td>\n",
       "      <td>[1923 world series - wikipedia. in the 1923 wo...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WebQTrn-3287_ebfe3c418f7914f9babf21caade27b05</td>\n",
       "      <td>[{'aliases': [], 'answer': 'Swedish krona', 'a...</td>\n",
       "      <td>sweden</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T01:34:14</td>\n",
       "      <td>what is the currency of the country that conta...</td>\n",
       "      <td>kronoberg county is part of the country using ...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-3287</td>\n",
       "      <td>what is the currency of sweden called</td>\n",
       "      <td>swedish krona</td>\n",
       "      <td>[Swedish krona]</td>\n",
       "      <td>[swedish krona]</td>\n",
       "      <td>Kronoberg County is part of the country using ...</td>\n",
       "      <td>[kronoberg county - wikipedia. kronoberg count...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WebQTest-1508_872253e47dd6ddaa213ff31eeda8783b</td>\n",
       "      <td>[{'aliases': ['Georgetown', 'Georgetown Univer...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-13T05:30:06</td>\n",
       "      <td>when did bill clinton go to college and the lo...</td>\n",
       "      <td>what college did bill clinton attend that is i...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTest-1508</td>\n",
       "      <td>when did bill clinton go to college</td>\n",
       "      <td>georgetown university</td>\n",
       "      <td>[Georgetown University, Georgetown, Georgetown...</td>\n",
       "      <td>[georgetown university, georgetown]</td>\n",
       "      <td>What college did Bill Clinton attend that is i...</td>\n",
       "      <td>[bill clinton - wikipedia. clinton was born an...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WebQTrn-2674_831fb3325644a924d433e2b267f6d238</td>\n",
       "      <td>[{'aliases': ['SC', 'Palmetto State'], 'answer...</td>\n",
       "      <td></td>\n",
       "      <td>conjunction</td>\n",
       "      <td>2018-02-13T00:25:17</td>\n",
       "      <td>where is usc from and is the us state that has...</td>\n",
       "      <td>which state includes a university that sometim...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTrn-2674</td>\n",
       "      <td>where is usc from</td>\n",
       "      <td>south carolina</td>\n",
       "      <td>[South Carolina, SC, Palmetto State]</td>\n",
       "      <td>[south carolina, sc, palmetto state]</td>\n",
       "      <td>Which state includes a university that sometim...</td>\n",
       "      <td>[university of southern california - wikipedia...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WebQTest-811_22a085e4a873315a9c2e63361cbd9248</td>\n",
       "      <td>[{'aliases': [], 'answer': 'Bright House Field...</td>\n",
       "      <td>phillies</td>\n",
       "      <td>composition</td>\n",
       "      <td>2018-02-13T04:11:56</td>\n",
       "      <td>where is the the team has a team moscot named ...</td>\n",
       "      <td>where is mascot phillie phanatic's team's spri...</td>\n",
       "      <td>PREFIX ns: &lt;http://rdf.freebase.com/ns/&gt;\\nSELE...</td>\n",
       "      <td>WebQTest-811</td>\n",
       "      <td>where is the phillies spring training stadium</td>\n",
       "      <td>bright house field</td>\n",
       "      <td>[Bright House Field]</td>\n",
       "      <td>[bright house field]</td>\n",
       "      <td>Where is mascot Phillie Phanatic's team's spri...</td>\n",
       "      <td>[phillie phanatic - wikipedia. the phillie pha...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ID  \\\n",
       "1    WebQTest-823_ed31f9dd431831dbd32a06b958c7c97c   \n",
       "2    WebQTrn-2181_8d86dc5e03446f0e50fd69bc06ae0658   \n",
       "3    WebQTrn-1447_f1ea2e60c0bd4311ef47cc0d7f6c0dd8   \n",
       "4     WebQTrn-453_2326103f221042f024262b19814ee9d3   \n",
       "5     WebQTrn-453_8c50e30ac5163e6dabfc999a7129a4ea   \n",
       "6    WebQTrn-1929_de8581ad379fdf8fb0e03c89e19ead1a   \n",
       "10   WebQTrn-3287_ebfe3c418f7914f9babf21caade27b05   \n",
       "12  WebQTest-1508_872253e47dd6ddaa213ff31eeda8783b   \n",
       "13   WebQTrn-2674_831fb3325644a924d433e2b267f6d238   \n",
       "15   WebQTest-811_22a085e4a873315a9c2e63361cbd9248   \n",
       "\n",
       "                                              answers composition_answer  \\\n",
       "1   [{'aliases': ['Brazilian ', 'República Federat...                      \n",
       "2   [{'aliases': [], 'answer': 'John Harbaugh', 'a...             ravens   \n",
       "3   [{'aliases': ['Braylon Jamel Edwards'], 'answe...                      \n",
       "4   [{'aliases': ['Kenya Shilling'], 'answer': 'Ke...              kenya   \n",
       "5   [{'aliases': ['Kenya Shilling'], 'answer': 'Ke...              kenya   \n",
       "6   [{'aliases': ['1923 World'], 'answer': '1923 W...            yankees   \n",
       "10  [{'aliases': [], 'answer': 'Swedish krona', 'a...             sweden   \n",
       "12  [{'aliases': ['Georgetown', 'Georgetown Univer...                      \n",
       "13  [{'aliases': ['SC', 'Palmetto State'], 'answer...                      \n",
       "15  [{'aliases': [], 'answer': 'Bright House Field...           phillies   \n",
       "\n",
       "   compositionality_type              created  \\\n",
       "1            conjunction  2018-02-13T04:12:26   \n",
       "2            composition  2018-02-12T23:32:26   \n",
       "3            comparative  2018-02-12T22:18:56   \n",
       "4            composition  2018-02-12T20:29:53   \n",
       "5            composition  2018-02-12T20:29:53   \n",
       "6            composition  2018-02-12T23:08:17   \n",
       "10           composition  2018-02-13T01:34:14   \n",
       "12           conjunction  2018-02-13T05:30:06   \n",
       "13           conjunction  2018-02-13T00:25:17   \n",
       "15           composition  2018-02-13T04:11:56   \n",
       "\n",
       "                                     machine_question  \\\n",
       "1   what does bolivia border and is the country th...   \n",
       "2   who is the the sports team owner is Steve Bisc...   \n",
       "3   who did the cleveland browns draft and is the ...   \n",
       "4   what currency do they accept in the country th...   \n",
       "5   what currency do they accept in the country th...   \n",
       "6   what year did the team won the 1999 World Seri...   \n",
       "10  what is the currency of the country that conta...   \n",
       "12  when did bill clinton go to college and the lo...   \n",
       "13  where is usc from and is the us state that has...   \n",
       "15  where is the the team has a team moscot named ...   \n",
       "\n",
       "                                             question  \\\n",
       "1   what country borders bolivia and contains goiã¡s?   \n",
       "2   who is the coach of the team owned by steve bi...   \n",
       "3   which professional athletes who began their ca...   \n",
       "4   the country that has the national anthem ee mu...   \n",
       "5   rift valley province is located in a nation th...   \n",
       "6   when did the champion of the 1999 world series...   \n",
       "10  kronoberg county is part of the country using ...   \n",
       "12  what college did bill clinton attend that is i...   \n",
       "13  which state includes a university that sometim...   \n",
       "15  where is mascot phillie phanatic's team's spri...   \n",
       "\n",
       "                                               sparql      webqsp_ID  \\\n",
       "1   PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTest-823   \n",
       "2   PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-2181   \n",
       "3   PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-1447   \n",
       "4   PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...    WebQTrn-453   \n",
       "5   PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...    WebQTrn-453   \n",
       "6   PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-1929   \n",
       "10  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-3287   \n",
       "12  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...  WebQTest-1508   \n",
       "13  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTrn-2674   \n",
       "15  PREFIX ns: <http://rdf.freebase.com/ns/>\\nSELE...   WebQTest-811   \n",
       "\n",
       "                                      webqsp_question                 answer  \\\n",
       "1                            what does bolivia border                 brazil   \n",
       "2                             who is the ravens coach          john harbaugh   \n",
       "3                  who did the cleveland browns draft             jeff faine   \n",
       "4               what currency do they accept in kenya        kenyan shilling   \n",
       "5               what currency do they accept in kenya        kenyan shilling   \n",
       "6   what year did yankees win their first world se...      1923 world series   \n",
       "10              what is the currency of sweden called          swedish krona   \n",
       "12                when did bill clinton go to college  georgetown university   \n",
       "13                                  where is usc from         south carolina   \n",
       "15      where is the phillies spring training stadium     bright house field   \n",
       "\n",
       "                                       merged_answers  \\\n",
       "1   [Brazil, Brazilian , República Federativa do B...   \n",
       "2                                     [John Harbaugh]   \n",
       "3                 [Jeff Faine, Braylon Jamel Edwards]   \n",
       "4                   [Kenyan shilling, Kenya Shilling]   \n",
       "5                   [Kenyan shilling, Kenya Shilling]   \n",
       "6                     [1923 World Series, 1923 World]   \n",
       "10                                    [Swedish krona]   \n",
       "12  [Georgetown University, Georgetown, Georgetown...   \n",
       "13               [South Carolina, SC, Palmetto State]   \n",
       "15                               [Bright House Field]   \n",
       "\n",
       "                  answers_shorter_than_n  \\\n",
       "1           [brazil, brazilian , brasil]   \n",
       "2                        [john harbaugh]   \n",
       "3    [jeff faine, braylon jamel edwards]   \n",
       "4      [kenyan shilling, kenya shilling]   \n",
       "5      [kenyan shilling, kenya shilling]   \n",
       "6        [1923 world series, 1923 world]   \n",
       "10                       [swedish krona]   \n",
       "12   [georgetown university, georgetown]   \n",
       "13  [south carolina, sc, palmetto state]   \n",
       "15                  [bright house field]   \n",
       "\n",
       "                                           question_y  \\\n",
       "1   What country borders Bolivia and contains GoiÃ¡s?   \n",
       "2   Who is the coach of the team owned by Steve Bi...   \n",
       "3   Which professional athletes who began their ca...   \n",
       "4   The country that has the national anthem Ee Mu...   \n",
       "5   Rift Valley Province is located in a nation th...   \n",
       "6   When did the champion of the 1999 World Series...   \n",
       "10  Kronoberg County is part of the country using ...   \n",
       "12  What college did Bill Clinton attend that is i...   \n",
       "13  Which state includes a university that sometim...   \n",
       "15  Where is mascot Phillie Phanatic's team's spri...   \n",
       "\n",
       "                                merged_top_k_snippets  num_of_merged_snippets  \\\n",
       "1   [category:borders of bolivia - wikipedia. page...                    50.0   \n",
       "2   [list of baltimore ravens head coaches - wikip...                    50.0   \n",
       "3   [what athletes started their career at a relat...                    50.0   \n",
       "4   [ee mungu nguvu yetu - wikipedia. ee mungu ngu...                    50.0   \n",
       "5   [rift valley province - wikipedia. rift valley...                    50.0   \n",
       "6   [1923 world series - wikipedia. in the 1923 wo...                    50.0   \n",
       "10  [kronoberg county - wikipedia. kronoberg count...                    50.0   \n",
       "12  [bill clinton - wikipedia. clinton was born an...                    50.0   \n",
       "13  [university of southern california - wikipedia...                    50.0   \n",
       "15  [phillie phanatic - wikipedia. the phillie pha...                    50.0   \n",
       "\n",
       "    have_explicit_ans_top_k  have_any_ans_top_k  \n",
       "1                      True                True  \n",
       "2                      True                True  \n",
       "3                      True                True  \n",
       "4                      True                True  \n",
       "5                      True                True  \n",
       "6                      True                True  \n",
       "10                     True                True  \n",
       "12                     True                True  \n",
       "13                     True                True  \n",
       "15                     True                True  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_ans_dev_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_ans_train_df_reduced = pd.DataFrame(existing_ans_train_df[[\"ID\", \"compositionality_type\", \"question\", \"answers_shorter_than_n\", \"merged_top_k_snippets\"]])\n",
    "existing_ans_dev_df_reduced = pd.DataFrame(existing_ans_dev_df[[\"ID\", \"compositionality_type\", \"question\", \"answers_shorter_than_n\", \"merged_top_k_snippets\"]])\n",
    "test_df_reduced = pd.DataFrame(test_questions_snippets[[\"ID\", \"compositionality_type\", \"question\", \"merged_top_k_snippets\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>compositionality_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answers_shorter_than_n</th>\n",
       "      <th>merged_top_k_snippets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WebQTest-823_ed31f9dd431831dbd32a06b958c7c97c</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>what country borders bolivia and contains goiã¡s?</td>\n",
       "      <td>[brazil, brazilian , brasil]</td>\n",
       "      <td>[category:borders of bolivia - wikipedia. page...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WebQTrn-2181_8d86dc5e03446f0e50fd69bc06ae0658</td>\n",
       "      <td>composition</td>\n",
       "      <td>who is the coach of the team owned by steve bi...</td>\n",
       "      <td>[john harbaugh]</td>\n",
       "      <td>[list of baltimore ravens head coaches - wikip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WebQTrn-1447_f1ea2e60c0bd4311ef47cc0d7f6c0dd8</td>\n",
       "      <td>comparative</td>\n",
       "      <td>which professional athletes who began their ca...</td>\n",
       "      <td>[jeff faine, braylon jamel edwards]</td>\n",
       "      <td>[what athletes started their career at a relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WebQTrn-453_2326103f221042f024262b19814ee9d3</td>\n",
       "      <td>composition</td>\n",
       "      <td>the country that has the national anthem ee mu...</td>\n",
       "      <td>[kenyan shilling, kenya shilling]</td>\n",
       "      <td>[ee mungu nguvu yetu - wikipedia. ee mungu ngu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WebQTrn-453_8c50e30ac5163e6dabfc999a7129a4ea</td>\n",
       "      <td>composition</td>\n",
       "      <td>rift valley province is located in a nation th...</td>\n",
       "      <td>[kenyan shilling, kenya shilling]</td>\n",
       "      <td>[rift valley province - wikipedia. rift valley...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WebQTrn-1929_de8581ad379fdf8fb0e03c89e19ead1a</td>\n",
       "      <td>composition</td>\n",
       "      <td>when did the champion of the 1999 world series...</td>\n",
       "      <td>[1923 world series, 1923 world]</td>\n",
       "      <td>[1923 world series - wikipedia. in the 1923 wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WebQTrn-3287_ebfe3c418f7914f9babf21caade27b05</td>\n",
       "      <td>composition</td>\n",
       "      <td>kronoberg county is part of the country using ...</td>\n",
       "      <td>[swedish krona]</td>\n",
       "      <td>[kronoberg county - wikipedia. kronoberg count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WebQTest-1508_872253e47dd6ddaa213ff31eeda8783b</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>what college did bill clinton attend that is i...</td>\n",
       "      <td>[georgetown university, georgetown]</td>\n",
       "      <td>[bill clinton - wikipedia. clinton was born an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WebQTrn-2674_831fb3325644a924d433e2b267f6d238</td>\n",
       "      <td>conjunction</td>\n",
       "      <td>which state includes a university that sometim...</td>\n",
       "      <td>[south carolina, sc, palmetto state]</td>\n",
       "      <td>[university of southern california - wikipedia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WebQTest-811_22a085e4a873315a9c2e63361cbd9248</td>\n",
       "      <td>composition</td>\n",
       "      <td>where is mascot phillie phanatic's team's spri...</td>\n",
       "      <td>[bright house field]</td>\n",
       "      <td>[phillie phanatic - wikipedia. the phillie pha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ID compositionality_type  \\\n",
       "1    WebQTest-823_ed31f9dd431831dbd32a06b958c7c97c           conjunction   \n",
       "2    WebQTrn-2181_8d86dc5e03446f0e50fd69bc06ae0658           composition   \n",
       "3    WebQTrn-1447_f1ea2e60c0bd4311ef47cc0d7f6c0dd8           comparative   \n",
       "4     WebQTrn-453_2326103f221042f024262b19814ee9d3           composition   \n",
       "5     WebQTrn-453_8c50e30ac5163e6dabfc999a7129a4ea           composition   \n",
       "6    WebQTrn-1929_de8581ad379fdf8fb0e03c89e19ead1a           composition   \n",
       "10   WebQTrn-3287_ebfe3c418f7914f9babf21caade27b05           composition   \n",
       "12  WebQTest-1508_872253e47dd6ddaa213ff31eeda8783b           conjunction   \n",
       "13   WebQTrn-2674_831fb3325644a924d433e2b267f6d238           conjunction   \n",
       "15   WebQTest-811_22a085e4a873315a9c2e63361cbd9248           composition   \n",
       "\n",
       "                                             question  \\\n",
       "1   what country borders bolivia and contains goiã¡s?   \n",
       "2   who is the coach of the team owned by steve bi...   \n",
       "3   which professional athletes who began their ca...   \n",
       "4   the country that has the national anthem ee mu...   \n",
       "5   rift valley province is located in a nation th...   \n",
       "6   when did the champion of the 1999 world series...   \n",
       "10  kronoberg county is part of the country using ...   \n",
       "12  what college did bill clinton attend that is i...   \n",
       "13  which state includes a university that sometim...   \n",
       "15  where is mascot phillie phanatic's team's spri...   \n",
       "\n",
       "                  answers_shorter_than_n  \\\n",
       "1           [brazil, brazilian , brasil]   \n",
       "2                        [john harbaugh]   \n",
       "3    [jeff faine, braylon jamel edwards]   \n",
       "4      [kenyan shilling, kenya shilling]   \n",
       "5      [kenyan shilling, kenya shilling]   \n",
       "6        [1923 world series, 1923 world]   \n",
       "10                       [swedish krona]   \n",
       "12   [georgetown university, georgetown]   \n",
       "13  [south carolina, sc, palmetto state]   \n",
       "15                  [bright house field]   \n",
       "\n",
       "                                merged_top_k_snippets  \n",
       "1   [category:borders of bolivia - wikipedia. page...  \n",
       "2   [list of baltimore ravens head coaches - wikip...  \n",
       "3   [what athletes started their career at a relat...  \n",
       "4   [ee mungu nguvu yetu - wikipedia. ee mungu ngu...  \n",
       "5   [rift valley province - wikipedia. rift valley...  \n",
       "6   [1923 world series - wikipedia. in the 1923 wo...  \n",
       "10  [kronoberg county - wikipedia. kronoberg count...  \n",
       "12  [bill clinton - wikipedia. clinton was born an...  \n",
       "13  [university of southern california - wikipedia...  \n",
       "15  [phillie phanatic - wikipedia. the phillie pha...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_ans_dev_df_reduced.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize words in questions, answers and snippets.\n",
    "\n",
    "Tokenize and Vectorize (keras encoded one-hot representation (each onehot vec represented as an int number)) text feature.\n",
    "\n",
    "See: https://keras.io/preprocessing/text/#one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, add <EOS> between each sentence endings. Sencond, translate: \"-\", \"_\" and \"\\xa0\" to \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "translation = {\"\\xa0\":\" \"}\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(translation)\n",
    "    text = ' '.join(word_tokenize(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [existing_ans_train_df_reduced, existing_ans_dev_df_reduced, test_df_reduced]:\n",
    "    df[\"question\"] = df.apply(lambda r: preprocess_text(r[\"question\"]), axis=1)\n",
    "    df[\"merged_top_k_snippets\"] = df.apply(lambda r: [preprocess_text(snip) for snip in r[\"merged_top_k_snippets\"]], axis=1)\n",
    "\n",
    "for df in [existing_ans_train_df_reduced, existing_ans_dev_df_reduced]:\n",
    "    df[\"answers_shorter_than_n\"] = df.apply(lambda r: [preprocess_text(ans) for ans in r[\"answers_shorter_than_n\"]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "oov_token = \"<UNK>\"\n",
    "max_num_of_words = 300000\n",
    "\n",
    "max_num_of_words = 300000\n",
    "# Kept punctuation (will be tokenized as seperate words): .,!?:;-_\n",
    "filtered_punctuation = '\"#$%&\\'()*+/<=>@[\\\\]^`{|}~'\n",
    "tokenizer = Tokenizer(filters=filtered_punctuation, \n",
    "                      lower=False, split=' ', char_level=False, \n",
    "                      num_words = max_num_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all text to fit tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_train = pd.DataFrame()\n",
    "all_text_train[\"all_text\"] = existing_ans_train_df_reduced.apply(\n",
    "        lambda r: [r[\"question\"]] + [snip for snip in r[\"merged_top_k_snippets\"]] + [ans for ans in r[\"answers_shorter_than_n\"]],\n",
    "        axis=1)\n",
    "\n",
    "all_text_dev = pd.DataFrame()\n",
    "all_text_dev[\"all_text\"] = existing_ans_dev_df_reduced.apply(\n",
    "        lambda r: [r[\"question\"]] + [snip for snip in r[\"merged_top_k_snippets\"]] + [ans for ans in r[\"answers_shorter_than_n\"]],\n",
    "        axis=1)\n",
    "\n",
    "all_text_test = pd.DataFrame()\n",
    "all_text_test[\"all_text\"] = test_df_reduced.apply(\n",
    "        lambda r: [r[\"question\"]] + [snip for snip in r[\"merged_top_k_snippets\"]],\n",
    "        axis=1)\n",
    "\n",
    "all_text = np.hstack([all_text_train[\"all_text\"], all_text_dev[\"all_text\"], all_text_test[\"all_text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text...\n",
      "Done tokenizing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Tokenizing text...')\n",
    "tokenizer.fit_on_texts(list(itertools.chain.from_iterable(all_text)))\n",
    "print('Done tokenizing.')\n",
    "\n",
    "del all_text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save tokenizer and reversed word_index map to file (for further prediction use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(DATA_PATH, FNAME_TOKENIZER), 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(DATA_PATH, FNAME_INVERSE_MAP), 'wb') as handle:\n",
    "    pickle.dump(reverse_word_map, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying tokenizer on train and dev texts and pad it to maxlen...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "maxlen_questions = 20\n",
    "maxlen_snippets = 100\n",
    "\n",
    "print('Applying tokenizer on train and dev texts and pad it to maxlen...')\n",
    "\n",
    "for df in [existing_ans_train_df_reduced, existing_ans_dev_df_reduced]:\n",
    "    df[\"tokenized_question\"] = tokenizer.texts_to_sequences(df[\"question\"])\n",
    "    df[\"tokenized_snippets\"] = df.apply(\n",
    "        lambda r : tokenizer.texts_to_sequences(r[\"merged_top_k_snippets\"]), axis=1)\n",
    "    df[\"tokenized_answers\"] = df.apply(\n",
    "        lambda r : tokenizer.texts_to_sequences(r[\"answers_shorter_than_n\"]), axis=1)\n",
    "\n",
    "    df[\"tokenized_question\"] = df.apply(\n",
    "        lambda r: pad_sequences([r[\"tokenized_question\"]], maxlen=maxlen_questions, padding='post', truncating='post')[0], axis=1)\n",
    "    df[\"tokenized_snippets\"] = df.apply(\n",
    "        lambda r: pad_sequences(r[\"tokenized_snippets\"], maxlen=maxlen_snippets, padding='post', truncating='post'), axis=1)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter all answers with more than (n+1)=4 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long_answers(answers):\n",
    "    res = []\n",
    "    for ans in answers:\n",
    "        if 0 < len(ans) <= 4:\n",
    "            res += [ans]\n",
    "    if len(res) == 0:\n",
    "        return np.nan\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in [existing_ans_train_df_reduced, existing_ans_dev_df_reduced]:\n",
    "    df[\"tokenized_answers\"] = df.apply(lambda r : filter_long_answers(r[\"tokenized_answers\"]), axis=1)\n",
    "    df.dropna(subset=['tokenized_answers'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize test texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying tokenizer on test texts and pad it to maxlen...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Applying tokenizer on test texts and pad it to maxlen...')\n",
    "\n",
    "test_df_reduced[\"tokenized_question\"] = tokenizer.texts_to_sequences(test_df_reduced[\"question\"])\n",
    "test_df_reduced[\"tokenized_snippets\"] = test_df_reduced.apply(\n",
    "    lambda r : tokenizer.texts_to_sequences(r[\"merged_top_k_snippets\"]), axis=1)\n",
    "\n",
    "test_df_reduced[\"tokenized_question\"] = test_df_reduced.apply(\n",
    "    lambda r: pad_sequences([r[\"tokenized_question\"]], maxlen=maxlen_questions, padding='post', truncating='post')[0], axis=1)\n",
    "test_df_reduced[\"tokenized_snippets\"] = test_df_reduced.apply(\n",
    "        lambda r: pad_sequences(r[\"tokenized_snippets\"], maxlen=maxlen_snippets, padding='post', truncating='post'), axis=1)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load word embeddings and arrange them in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings.\n",
      "\n",
      "Done loading GloVe embeddings!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading GloVe embeddings.\\n\")\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(DATA_PATH, FNAME_EMBEDDINGS), \"r\") as glove_ds_sample:\n",
    "    for line in glove_ds_sample.readlines():\n",
    "        line = line.strip().split()\n",
    "        word = line[0].lower()\n",
    "        embeddings_index[word] = np.array([float(x) for x in line[1:]])\n",
    "print(\"Done loading GloVe embeddings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Glove embedding matrix that matches the tokenizer's word indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding matrix...\n",
      "There are total of 683359 words in our corpus.\n",
      "There are 400000 embeddings in Glove.\n",
      "We have embeddings for 213056 words (31.177755762344535% existing embeddings).\n",
      "Embedding is missing for 470303 words.\n",
      "\n",
      "\n",
      "Done loading embeddings.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 2\n",
    "embedding_matrix = np.random.rand(vocab_size, EMBEDDING_DIM)\n",
    "\n",
    "print('Creating embedding matrix...')\n",
    "embedding_exists = 0\n",
    "no_embeddings = 0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embeddings_index:\n",
    "        embedding_matrix[i] = embeddings_index[word]\n",
    "        embedding_exists += 1\n",
    "    else:\n",
    "        no_embeddings += 1\n",
    "\n",
    "print (\"There are total of {} words in our corpus.\".format(embedding_exists+no_embeddings))\n",
    "print (\"There are {} embeddings in Glove.\".format(len(embeddings_index)))\n",
    "print (\"We have embeddings for {} words ({}% existing embeddings).\".format(embedding_exists, \\\n",
    "                                                                           (100*embedding_exists/(embedding_exists+no_embeddings))))\n",
    "print (\"Embedding is missing for {} words.\".format(no_embeddings))\n",
    "\n",
    "del embeddings_index\n",
    "gc.collect()\n",
    "\n",
    "print('\\n\\nDone loading embeddings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero (0) index of the embedding_matrix will be a zero (non trainable) vector that is reserved for the padding token.\n",
    "We concat this zero vector in the TF code (not here).\n",
    "It's Important that it will be a zero vector that it does not effect the RNN until it reaches the real words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.delete(embedding_matrix, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.dump(os.path.join(DATA_PATH, FNAME_TOKEN_EMBEDDING_MAT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer vectors for snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate possible answeres based on the dataset snippets. Each question will have two answer vectors: \"answer_start\" and \"answer_end\". Those are binary vectors. For each index of an answer's start in a snippet we will have \"1\" in \"answer_start\" vector and respectively \"1\" for every index where we have an answer's end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_gram(label, answer, texts, gram):\n",
    "    answer = np.array(answer)\n",
    "    text_len = len(texts[0]) - gram + 1\n",
    "    for text_i, text in enumerate(texts):\n",
    "        text1 = np.array(text)\n",
    "        for i in range(len(text) - gram + 1):\n",
    "            if np.array_equal(text[i:i + gram], answer):\n",
    "                label[text_i * text_len + i] = 1\n",
    "    return label\n",
    "\n",
    "def get_label(texts, answers):\n",
    "    texts = np.asarray(texts)\n",
    "    label_unigram = np.zeros(len(texts[0]) * len(texts))\n",
    "    label_bigram = np.zeros((len(texts[0]) - 1) * len(texts))\n",
    "    label_trigram = np.zeros((len(texts[0]) - 2) * len(texts))\n",
    "    label_fourgram = np.zeros((len(texts[0]) - 3) * len(texts))\n",
    "    for answer in answers:\n",
    "        answer_len = len(answer)\n",
    "        if answer_len == 1:\n",
    "            label_unigram = create_label_gram(label_unigram, answer, texts, 1)\n",
    "        elif answer_len == 2:\n",
    "            label_bigram = create_label_gram(label_bigram, answer, texts, 2)\n",
    "        elif answer_len == 3:\n",
    "            label_trigram = create_label_gram(label_trigram, answer, texts, 3)\n",
    "        elif answer_len == 4:\n",
    "            label_fourgram = create_label_gram(label_fourgram, answer, texts, 4)\n",
    "        else:\n",
    "            print(\"ERROR: {}\".format(answer))\n",
    "\n",
    "    return np.concatenate((label_unigram, label_bigram, label_trigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/18268 [00:00<25:50, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answer vectors for train and dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18268/18268 [22:12<00:00, 13.71it/s]\n",
      "100%|██████████| 2374/2374 [03:10<00:00,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "print('Generating answer vectors for train and dev.')\n",
    "\n",
    "for df in [existing_ans_train_df_reduced, existing_ans_dev_df_reduced]:\n",
    "    df[\"answers\"] = df.progress_apply(\n",
    "        lambda r : get_label(r[\"tokenized_snippets\"], r[\"tokenized_answers\"]), axis=1)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename and save train, dev, test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_questions = pd.DataFrame(existing_ans_train_df_reduced[[\"ID\", \"compositionality_type\", \"tokenized_question\",\"answers\"]])\n",
    "final_dev_questions = pd.DataFrame(existing_ans_dev_df_reduced[[\"ID\", \"compositionality_type\", \"tokenized_question\",\"answers\"]])\n",
    "final_test_questions = pd.DataFrame(test_df_reduced[[\"ID\", \"compositionality_type\", \"tokenized_question\"]])\n",
    "\n",
    "final_train_snippets = pd.DataFrame(existing_ans_train_df_reduced[[\"ID\", \"tokenized_snippets\"]])\n",
    "final_dev_snippets = pd.DataFrame(existing_ans_dev_df_reduced[[\"ID\", \"tokenized_snippets\"]])\n",
    "final_test_snippets = pd.DataFrame(test_df_reduced[[\"ID\", \"tokenized_snippets\"]])\n",
    "\n",
    "final_train_questions.rename(index=str, columns={\"tokenized_question\": \"question\"}, inplace=True)\n",
    "final_dev_questions.rename(index=str, columns={\"tokenized_question\": \"question\"}, inplace=True)\n",
    "final_test_questions.rename(index=str, columns={\"tokenized_question\": \"question\"}, inplace=True)\n",
    "\n",
    "for df in [final_train_snippets, final_dev_snippets, final_test_snippets]:\n",
    "    df.rename(index=str, columns={\"tokenized_snippets\": \"snippets\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_questions.to_json(os.path.join(DATA_PATH, \"final_train_questions.json.gz\"), orient='records', compression='gzip')\n",
    "final_dev_questions.to_json(os.path.join(DATA_PATH, \"final_dev_questions.json.gz\"), orient='records', compression='gzip')\n",
    "final_test_questions.to_json(os.path.join(DATA_PATH, \"final_test_questions.json.gz\"), orient='records', compression='gzip')\n",
    "final_train_snippets.to_json(os.path.join(DATA_PATH, \"final_train_snippets.json.gz\"), orient='records', compression='gzip')\n",
    "final_dev_snippets.to_json(os.path.join(DATA_PATH, \"final_dev_snippets.json.gz\"), orient='records', compression='gzip')\n",
    "final_test_snippets.to_json(os.path.join(DATA_PATH, \"final_test_snippets.json.gz\"), orient='records', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_questions[:100].to_json(os.path.join(DATA_PATH, \"final_train_questions_100.json.gz\"), orient='records', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>compositionality_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answers_shorter_than_n</th>\n",
       "      <th>merged_top_k_snippets</th>\n",
       "      <th>tokenized_question</th>\n",
       "      <th>tokenized_snippets</th>\n",
       "      <th>tokenized_answers</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WebQTrn-3513_7c4117891abf63781b892537979054c6</td>\n",
       "      <td>composition</td>\n",
       "      <td>what state is home to the university that is r...</td>\n",
       "      <td>[washington , d.c ., washington d.c ., washing...</td>\n",
       "      <td>[gwsports.com mike lonergan bio : : george was...</td>\n",
       "      <td>[64, 51, 11, 148, 10, 1, 87, 20, 11, 2070, 7, ...</td>\n",
       "      <td>[[45179, 1500, 28639, 2680, 12, 12, 411, 308, ...</td>\n",
       "      <td>[[308, 2, 13212, 3], [308, 13212, 3], [308], [...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ID compositionality_type  \\\n",
       "0  WebQTrn-3513_7c4117891abf63781b892537979054c6           composition   \n",
       "\n",
       "                                            question  \\\n",
       "0  what state is home to the university that is r...   \n",
       "\n",
       "                              answers_shorter_than_n  \\\n",
       "0  [washington , d.c ., washington d.c ., washing...   \n",
       "\n",
       "                               merged_top_k_snippets  \\\n",
       "0  [gwsports.com mike lonergan bio : : george was...   \n",
       "\n",
       "                                  tokenized_question  \\\n",
       "0  [64, 51, 11, 148, 10, 1, 87, 20, 11, 2070, 7, ...   \n",
       "\n",
       "                                  tokenized_snippets  \\\n",
       "0  [[45179, 1500, 28639, 2680, 12, 12, 411, 308, ...   \n",
       "\n",
       "                                   tokenized_answers  \\\n",
       "0  [[308, 2, 13212, 3], [308, 13212, 3], [308], [...   \n",
       "\n",
       "                                             answers  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_ans_train_df_reduced.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2018)",
   "language": "python",
   "name": "intel_distribution_of_python_3_2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
